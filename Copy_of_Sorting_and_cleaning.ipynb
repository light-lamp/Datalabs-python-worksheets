{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Sorting_and_cleaning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/light-lamp/Datalabs-python-worksheets/blob/main/Copy_of_Sorting_and_cleaning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CVoh0pMzW0l"
      },
      "source": [
        "# Sorting and cleaning \n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "In order to effectively analyse a dataset, often we need to prepare it first. \n",
        "Before a dataset is ready to be analysed we might need to:  \n",
        "\n",
        "* sort the data (can be a series or dataframe)  \n",
        "* remove any NaN values or drop NA values   \n",
        "* remove duplicate records (identical rows)  \n",
        "* normalise data in dataframe columns so that has a common scale [reference](https://towardsai.net/p/data-science/how-when-and-why-should-you-normalize-standardize-rescale-your-data-3f083def38ff#:~:text=Similarly%2C%20the%20goal%20of%20normalization,dataset%20does%20not%20require%20normalization.&text=So%20we%20normalize%20the%20data,variables%20to%20the%20same%20range.)\n",
        "\n",
        "## Sorting the data  \n",
        "---\n",
        "\n",
        "\n",
        "Typically we want to sort data by the values in one or more columns in the dataframe  \n",
        "\n",
        "To sort the dataframe by series we use the pandas function **sort_values()**.  \n",
        "\n",
        "By default `sort_values()` sorts into ascending order.\n",
        "\n",
        "* sort by a single column e.g.\n",
        "  * `df.sort_values(\"Make\") `\n",
        "* sort by multiple columns e.g. \n",
        "  * `df.sort_values(by = [\"Model\", \"Make\"]) `\n",
        "    * this sorts by Model, then my Make \n",
        "* sort in *descending* order\n",
        "  * `df.sort_values(by = \"Make\", ascending = False)`\n",
        "  * `df.sort_values(by = [\"Make\", \"Model\"], ascending = False])`  \n",
        "\n",
        "Dataframes are mostly immutable, changes like sort_values do not change the dataframe permanently, they just change it for the time that the instruction is being used.\n",
        "\n",
        "`df.sort_values(by='Make')` *dataframe is now in sorted order and can be copied to a new dataframe*  \n",
        "`df` *original dataframe, df, will be as it was - unsorted* \n",
        "\n",
        "To split the dataframe after sorting, do this in the same instruction, e.g.:\n",
        "\n",
        "`df.sort_values(by = [\"Make\", \"Model\"], ascending = False])[[\"Make\", \"Model\"]]`\n",
        "\n",
        "This sorts on Make and then Model in descending order, then splits off the Make and Model columns.\n",
        "\n",
        "`df.sort_values(by = [\"Make\", \"Model\"], ascending = False])[[\"Make\", \"Model\"]].head()`\n",
        "\n",
        "This sorts on Make and then Model, then splits off the Make and Model columns and then splits off the first 5 rows."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANKknIx8E-hN"
      },
      "source": [
        "### Exercise 1 - get data, sort by happiness score \n",
        "---\n",
        "\n",
        "Read data from the Excel file on Happiness Data at this link: https://github.com/futureCodersSE/working-with-data/blob/main/Happiness-Data/2015.xlsx?raw=true\n",
        "\n",
        "Display first 5 rows of data  \n",
        "\n",
        "The data is currently sorted by Happiness Rank...\n",
        "*  sort the data by Happiness Score in ascending order\n",
        "*  display sorted table\n",
        "\n",
        "**Test output**:  \n",
        "The lowest score (displayed first) is 2.839, Togo  \n",
        "The highest score (displayed last) is 7.587, Switzerland  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkvFGvJtHXiH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "cc4d221a-ae59-4c64-b28a-3cdb50025609"
      },
      "source": [
        "import pandas as pd\n",
        "happiness = pd.read_excel(\"https://github.com/futureCodersSE/working-with-data/blob/main/Happiness-Data/2015.xlsx?raw=true\")\n",
        "happiness.head()\n",
        "new_happiness = happiness.sort_values(\"Happiness Score\")\n",
        "new_happiness"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Country</th>\n",
              "      <th>Region</th>\n",
              "      <th>Happiness Rank</th>\n",
              "      <th>Happiness Score</th>\n",
              "      <th>Standard Error</th>\n",
              "      <th>Economy (GDP per Capita)</th>\n",
              "      <th>Family</th>\n",
              "      <th>Health (Life Expectancy)</th>\n",
              "      <th>Freedom</th>\n",
              "      <th>Trust (Government Corruption)</th>\n",
              "      <th>Generosity</th>\n",
              "      <th>Dystopia Residual</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>157</th>\n",
              "      <td>Togo</td>\n",
              "      <td>Sub-Saharan Africa</td>\n",
              "      <td>158</td>\n",
              "      <td>2.839</td>\n",
              "      <td>0.06727</td>\n",
              "      <td>0.20868</td>\n",
              "      <td>0.13995</td>\n",
              "      <td>0.28443</td>\n",
              "      <td>0.36453</td>\n",
              "      <td>0.10731</td>\n",
              "      <td>0.16681</td>\n",
              "      <td>1.56726</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>156</th>\n",
              "      <td>Burundi</td>\n",
              "      <td>Sub-Saharan Africa</td>\n",
              "      <td>157</td>\n",
              "      <td>2.905</td>\n",
              "      <td>0.08658</td>\n",
              "      <td>0.01530</td>\n",
              "      <td>0.41587</td>\n",
              "      <td>0.22396</td>\n",
              "      <td>0.11850</td>\n",
              "      <td>0.10062</td>\n",
              "      <td>0.19727</td>\n",
              "      <td>1.83302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>155</th>\n",
              "      <td>Syria</td>\n",
              "      <td>Middle East and Northern Africa</td>\n",
              "      <td>156</td>\n",
              "      <td>3.006</td>\n",
              "      <td>0.05015</td>\n",
              "      <td>0.66320</td>\n",
              "      <td>0.47489</td>\n",
              "      <td>0.72193</td>\n",
              "      <td>0.15684</td>\n",
              "      <td>0.18906</td>\n",
              "      <td>0.47179</td>\n",
              "      <td>0.32858</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>154</th>\n",
              "      <td>Benin</td>\n",
              "      <td>Sub-Saharan Africa</td>\n",
              "      <td>155</td>\n",
              "      <td>3.340</td>\n",
              "      <td>0.03656</td>\n",
              "      <td>0.28665</td>\n",
              "      <td>0.35386</td>\n",
              "      <td>0.31910</td>\n",
              "      <td>0.48450</td>\n",
              "      <td>0.08010</td>\n",
              "      <td>0.18260</td>\n",
              "      <td>1.63328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153</th>\n",
              "      <td>Rwanda</td>\n",
              "      <td>Sub-Saharan Africa</td>\n",
              "      <td>154</td>\n",
              "      <td>3.465</td>\n",
              "      <td>0.03464</td>\n",
              "      <td>0.22208</td>\n",
              "      <td>0.77370</td>\n",
              "      <td>0.42864</td>\n",
              "      <td>0.59201</td>\n",
              "      <td>0.55191</td>\n",
              "      <td>0.22628</td>\n",
              "      <td>0.67042</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Canada</td>\n",
              "      <td>North America</td>\n",
              "      <td>5</td>\n",
              "      <td>7.427</td>\n",
              "      <td>0.03553</td>\n",
              "      <td>1.32629</td>\n",
              "      <td>1.32261</td>\n",
              "      <td>0.90563</td>\n",
              "      <td>0.63297</td>\n",
              "      <td>0.32957</td>\n",
              "      <td>0.45811</td>\n",
              "      <td>2.45176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Norway</td>\n",
              "      <td>Western Europe</td>\n",
              "      <td>4</td>\n",
              "      <td>7.522</td>\n",
              "      <td>0.03880</td>\n",
              "      <td>1.45900</td>\n",
              "      <td>1.33095</td>\n",
              "      <td>0.88521</td>\n",
              "      <td>0.66973</td>\n",
              "      <td>0.36503</td>\n",
              "      <td>0.34699</td>\n",
              "      <td>2.46531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Denmark</td>\n",
              "      <td>Western Europe</td>\n",
              "      <td>3</td>\n",
              "      <td>7.527</td>\n",
              "      <td>0.03328</td>\n",
              "      <td>1.32548</td>\n",
              "      <td>1.36058</td>\n",
              "      <td>0.87464</td>\n",
              "      <td>0.64938</td>\n",
              "      <td>0.48357</td>\n",
              "      <td>0.34139</td>\n",
              "      <td>2.49204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Iceland</td>\n",
              "      <td>Western Europe</td>\n",
              "      <td>2</td>\n",
              "      <td>7.561</td>\n",
              "      <td>0.04884</td>\n",
              "      <td>1.30232</td>\n",
              "      <td>1.40223</td>\n",
              "      <td>0.94784</td>\n",
              "      <td>0.62877</td>\n",
              "      <td>0.14145</td>\n",
              "      <td>0.43630</td>\n",
              "      <td>2.70201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Switzerland</td>\n",
              "      <td>Western Europe</td>\n",
              "      <td>1</td>\n",
              "      <td>7.587</td>\n",
              "      <td>0.03411</td>\n",
              "      <td>1.39651</td>\n",
              "      <td>1.34951</td>\n",
              "      <td>0.94143</td>\n",
              "      <td>0.66557</td>\n",
              "      <td>0.41978</td>\n",
              "      <td>0.29678</td>\n",
              "      <td>2.51738</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>158 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         Country  ... Dystopia Residual\n",
              "157         Togo  ...           1.56726\n",
              "156      Burundi  ...           1.83302\n",
              "155        Syria  ...           0.32858\n",
              "154        Benin  ...           1.63328\n",
              "153       Rwanda  ...           0.67042\n",
              "..           ...  ...               ...\n",
              "4         Canada  ...           2.45176\n",
              "3         Norway  ...           2.46531\n",
              "2        Denmark  ...           2.49204\n",
              "1        Iceland  ...           2.70201\n",
              "0    Switzerland  ...           2.51738\n",
              "\n",
              "[158 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_iomqRTH8LA"
      },
      "source": [
        "### Exercise 2 - sort by multiple columns, display the first 5 rows \n",
        "---\n",
        "\n",
        "1. sort the data by Economy (GDP per Capita) and Health (Life Expectancy) in ascending order \n",
        "2. display the first 5 rows of sorted data \n",
        "\n",
        "**Test output**:  \n",
        "Records 122, 127, 147, 100, 96"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7XalX7OK0u-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "096489c8-59d4-49cf-8e84-10aa3a08a34a"
      },
      "source": [
        "import pandas as pd\n",
        "happiness = pd.read_excel(\"https://github.com/futureCodersSE/working-with-data/blob/main/Happiness-Data/2015.xlsx?raw=true\")\n",
        "new_happiness = happiness.sort_values(by = [\"Economy (GDP per Capita)\", \"Health (Life Expectancy)\"]) [[\"Economy (GDP per Capita)\", \"Health (Life Expectancy)\"]]\n",
        "new_happiness.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Economy (GDP per Capita)</th>\n",
              "      <th>Health (Life Expectancy)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.09806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>156</th>\n",
              "      <td>0.01530</td>\n",
              "      <td>0.22396</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>130</th>\n",
              "      <td>0.01604</td>\n",
              "      <td>0.22562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>143</th>\n",
              "      <td>0.06940</td>\n",
              "      <td>0.29707</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115</th>\n",
              "      <td>0.07120</td>\n",
              "      <td>0.34201</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Economy (GDP per Capita)  Health (Life Expectancy)\n",
              "119                   0.00000                   0.09806\n",
              "156                   0.01530                   0.22396\n",
              "130                   0.01604                   0.22562\n",
              "143                   0.06940                   0.29707\n",
              "115                   0.07120                   0.34201"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfQ3cys4LHNc"
      },
      "source": [
        "### Exercise 3 - sorting in descending order \n",
        "---\n",
        " \n",
        "Sort the data by Freedom and Trust (Government Corruption) in descending order and show the Country and Region only for the last five rows\n",
        "\n",
        "**Test output**:\n",
        "43, 7, 144, 0, 3 Country and Region columns\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3haPVvX7MCom",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "09da4a7e-5194-4d30-ef58-c4eac0fe538c"
      },
      "source": [
        "import pandas as pd\n",
        "happiness = pd.read_excel(\"https://github.com/futureCodersSE/working-with-data/blob/main/Happiness-Data/2015.xlsx?raw=true\")\n",
        "new_happiness = happiness.sort_values(by = [\"Freedom\",\"Trust (Government Corruption)\"], ascending = False) [[\"Country\", \"Region\"]].tail()\n",
        "new_happiness\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Country</th>\n",
              "      <th>Region</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>136</th>\n",
              "      <td>Angola</td>\n",
              "      <td>Sub-Saharan Africa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117</th>\n",
              "      <td>Sudan</td>\n",
              "      <td>Sub-Saharan Africa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>Bosnia and Herzegovina</td>\n",
              "      <td>Central and Eastern Europe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>Greece</td>\n",
              "      <td>Western Europe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111</th>\n",
              "      <td>Iraq</td>\n",
              "      <td>Middle East and Northern Africa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    Country                           Region\n",
              "136                  Angola               Sub-Saharan Africa\n",
              "117                   Sudan               Sub-Saharan Africa\n",
              "95   Bosnia and Herzegovina       Central and Eastern Europe\n",
              "101                  Greece                   Western Europe\n",
              "111                    Iraq  Middle East and Northern Africa"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqnAoELjMDs7"
      },
      "source": [
        "# Cleaning the data\n",
        "\n",
        "Data comes from a range of sources:  forms, monitoring devices, etc.  There will often be missing values, duplicate records and values that are incorrectly formatted.  These can affect summary statistics and graphs plotted from the data.\n",
        "\n",
        "Techniques for data cleansing include:\n",
        "*  removing records with missing or null data (NaN, NA, \"\")\n",
        "*  removing duplicate rows (keeping just one, either the first or the last)\n",
        "\n",
        "Removal of rows according to criteria, or of columns are other ways that data might be cleaned up.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVqmfM5wk7NK"
      },
      "source": [
        "---\n",
        "\n",
        "## Removing NaN/Dropping NA values \n",
        "\n",
        "pandas have functions for checking a dataframe, or column, for null values, checking a column for missing values, and functions for dropping all rows that contain null values.\n",
        "\n",
        "* check for NA/NaN/missing values across dataframe (returns True if NA values exist)  \n",
        "  `df.isnull().values.any()`  \n",
        "\n",
        "* check for NA/NaN/missing values in specific column  \n",
        "  `df[\"Make\"].isnull().values.any()`  \n",
        "\n",
        "* drop all rows that have NA/NaN values   \n",
        "  `df.dropna()`  \n",
        "\n",
        "* drop rows where NA/NaN values exist in specific columns  \n",
        "  `df.dropna(subset = [\"Make\", \"Model\"])`  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DC65hEZGOKNL"
      },
      "source": [
        "### Exercise 4 - check for null values \n",
        "---\n",
        "\n",
        "1. read data from the file housing_in_london_yearly_variables.csv from this link: https://raw.githubusercontent.com/futureCodersSE/working-with-data/main/Data%20sets/housing_in_london_yearly_variables.csv \n",
        "2. check if any NA values exist in the dataframe and print the result \n",
        "3. use df.info() to see which columns have null entries (*Hint: if the non-null count is less than total entries, column contains missing/NA entries*)  \n",
        "\n",
        "**Test output**:\n",
        "True\n",
        ".info shows median_salary, life_satisfaction, recycling_pct, population_size, number_of_jobs, area_size, no_of_houses all less than total rows (1071) \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7LYkXDNVVc9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "048c0475-154c-4ee2-90ba-39f24060f2f4"
      },
      "source": [
        "import pandas as pd\n",
        "london_housing = pd.read_csv(\"https://raw.githubusercontent.com/futureCodersSE/working-with-data/main/Data%20sets/housing_in_london_yearly_variables.csv\")\n",
        "#london_housing.shape\n",
        "london_housing.isnull().values.any()\n",
        "london_housing.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1071 entries, 0 to 1070\n",
            "Data columns (total 12 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   code               1071 non-null   object \n",
            " 1   area               1071 non-null   object \n",
            " 2   date               1071 non-null   object \n",
            " 3   median_salary      1049 non-null   float64\n",
            " 4   life_satisfaction  352 non-null    float64\n",
            " 5   mean_salary        1071 non-null   object \n",
            " 6   recycling_pct      860 non-null    object \n",
            " 7   population_size    1018 non-null   float64\n",
            " 8   number_of_jobs     931 non-null    float64\n",
            " 9   area_size          666 non-null    float64\n",
            " 10  no_of_houses       666 non-null    float64\n",
            " 11  borough_flag       1071 non-null   int64  \n",
            "dtypes: float64(6), int64(1), object(5)\n",
            "memory usage: 100.5+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRBLm_bJVItu"
      },
      "source": [
        "### Exercise 5 - remove null values \n",
        "---\n",
        "\n",
        "1. remove rows with NA values for `life_satisfaction` (use [ ] even if only one column in list)\n",
        "2. remove all NA values across whole dataframe \n",
        "\n",
        "**Test output**:  \n",
        "1.  Row count reduced to 352 rows\n",
        "2.  Row count reduced to 267 rows"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjZJNIC3QObK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "b21d9ccb-862b-4755-b107-81cb3c5bce5c"
      },
      "source": [
        "import pandas as pd\n",
        "london_housing = pd.read_csv(\"https://raw.githubusercontent.com/futureCodersSE/working-with-data/main/Data%20sets/housing_in_london_yearly_variables.csv\")\n",
        "#london_housing.shape\n",
        "london_housing.isnull().values.any()\n",
        "# new_lh=london_housing.dropna(subset=[\"life_satisfaction\"])\n",
        "# new_lh\n",
        "london_housing.dropna()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>code</th>\n",
              "      <th>area</th>\n",
              "      <th>date</th>\n",
              "      <th>median_salary</th>\n",
              "      <th>life_satisfaction</th>\n",
              "      <th>mean_salary</th>\n",
              "      <th>recycling_pct</th>\n",
              "      <th>population_size</th>\n",
              "      <th>number_of_jobs</th>\n",
              "      <th>area_size</th>\n",
              "      <th>no_of_houses</th>\n",
              "      <th>borough_flag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>613</th>\n",
              "      <td>E09000002</td>\n",
              "      <td>barking and dagenham</td>\n",
              "      <td>2011-12-01</td>\n",
              "      <td>28201.0</td>\n",
              "      <td>7.05</td>\n",
              "      <td>33568</td>\n",
              "      <td>30</td>\n",
              "      <td>187029.0</td>\n",
              "      <td>54000.0</td>\n",
              "      <td>3780.0</td>\n",
              "      <td>71079.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>614</th>\n",
              "      <td>E09000003</td>\n",
              "      <td>barnet</td>\n",
              "      <td>2011-12-01</td>\n",
              "      <td>30237.0</td>\n",
              "      <td>7.43</td>\n",
              "      <td>33062</td>\n",
              "      <td>34</td>\n",
              "      <td>357538.0</td>\n",
              "      <td>147000.0</td>\n",
              "      <td>8675.0</td>\n",
              "      <td>139346.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>615</th>\n",
              "      <td>E09000004</td>\n",
              "      <td>bexley</td>\n",
              "      <td>2011-12-01</td>\n",
              "      <td>28638.0</td>\n",
              "      <td>7.42</td>\n",
              "      <td>31812</td>\n",
              "      <td>54</td>\n",
              "      <td>232774.0</td>\n",
              "      <td>78000.0</td>\n",
              "      <td>6429.0</td>\n",
              "      <td>95037.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>616</th>\n",
              "      <td>E09000005</td>\n",
              "      <td>brent</td>\n",
              "      <td>2011-12-01</td>\n",
              "      <td>26772.0</td>\n",
              "      <td>7.11</td>\n",
              "      <td>29609</td>\n",
              "      <td>37</td>\n",
              "      <td>312245.0</td>\n",
              "      <td>115000.0</td>\n",
              "      <td>4323.0</td>\n",
              "      <td>112083.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>617</th>\n",
              "      <td>E09000006</td>\n",
              "      <td>bromley</td>\n",
              "      <td>2011-12-01</td>\n",
              "      <td>28163.0</td>\n",
              "      <td>7.50</td>\n",
              "      <td>32863</td>\n",
              "      <td>50</td>\n",
              "      <td>310554.0</td>\n",
              "      <td>119000.0</td>\n",
              "      <td>15013.0</td>\n",
              "      <td>135036.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>E09000031</td>\n",
              "      <td>waltham forest</td>\n",
              "      <td>2018-12-01</td>\n",
              "      <td>30298.0</td>\n",
              "      <td>7.46</td>\n",
              "      <td>32875</td>\n",
              "      <td>32</td>\n",
              "      <td>276700.0</td>\n",
              "      <td>88000.0</td>\n",
              "      <td>3881.0</td>\n",
              "      <td>103029.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1000</th>\n",
              "      <td>E09000032</td>\n",
              "      <td>wandsworth</td>\n",
              "      <td>2018-12-01</td>\n",
              "      <td>34501.0</td>\n",
              "      <td>7.65</td>\n",
              "      <td>45317</td>\n",
              "      <td>23</td>\n",
              "      <td>326474.0</td>\n",
              "      <td>147000.0</td>\n",
              "      <td>3522.0</td>\n",
              "      <td>146162.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1001</th>\n",
              "      <td>E09000033</td>\n",
              "      <td>westminster</td>\n",
              "      <td>2018-12-01</td>\n",
              "      <td>43015.0</td>\n",
              "      <td>7.66</td>\n",
              "      <td>63792</td>\n",
              "      <td>22</td>\n",
              "      <td>255324.0</td>\n",
              "      <td>775000.0</td>\n",
              "      <td>2203.0</td>\n",
              "      <td>124509.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1008</th>\n",
              "      <td>E12000007</td>\n",
              "      <td>london</td>\n",
              "      <td>2018-12-01</td>\n",
              "      <td>38146.0</td>\n",
              "      <td>7.58</td>\n",
              "      <td>52629</td>\n",
              "      <td>33</td>\n",
              "      <td>8908081.0</td>\n",
              "      <td>6148000.0</td>\n",
              "      <td>159471.0</td>\n",
              "      <td>3556161.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1013</th>\n",
              "      <td>E92000001</td>\n",
              "      <td>england</td>\n",
              "      <td>2018-12-01</td>\n",
              "      <td>29856.0</td>\n",
              "      <td>7.71</td>\n",
              "      <td>37313</td>\n",
              "      <td>44</td>\n",
              "      <td>55977178.0</td>\n",
              "      <td>30493000.0</td>\n",
              "      <td>13303728.0</td>\n",
              "      <td>24172166.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>267 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           code                  area  ... no_of_houses  borough_flag\n",
              "613   E09000002  barking and dagenham  ...      71079.0             1\n",
              "614   E09000003                barnet  ...     139346.0             1\n",
              "615   E09000004                bexley  ...      95037.0             1\n",
              "616   E09000005                 brent  ...     112083.0             1\n",
              "617   E09000006               bromley  ...     135036.0             1\n",
              "...         ...                   ...  ...          ...           ...\n",
              "999   E09000031        waltham forest  ...     103029.0             1\n",
              "1000  E09000032            wandsworth  ...     146162.0             1\n",
              "1001  E09000033           westminster  ...     124509.0             1\n",
              "1008  E12000007                london  ...    3556161.0             0\n",
              "1013  E92000001               england  ...   24172166.0             0\n",
              "\n",
              "[267 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ui8HF5z8SiK8"
      },
      "source": [
        "## Dropping duplicates\n",
        "---\n",
        "\n",
        "* To remove duplicate rows based on duplication of values in all columns  \n",
        "  `df.drop_duplicates()`  \n",
        "\n",
        "* To remove rows that have duplicate entries in a specified column  \n",
        "  `df.drop_duplicates(subset = ['Make'])`  \n",
        "\n",
        "* To remove rows that have duplicate entries in multiple columns  \n",
        "  `df.drop_duplicates(subset = ['Make', 'Model'])` \n",
        "\n",
        "* Remove duplicate rows keeping the last instance rather than the first (default):  \n",
        "  `df.drop_duplicates(keep='last')`  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2Qf6uMxSb5t"
      },
      "source": [
        "### Exercise 6 - Removing duplicate entries \n",
        "---\n",
        "\n",
        "remove duplicate `area` entries keeping first instance  \n",
        "\n",
        "**Test output**:  \n",
        " Dataframe now contains 50 rows all with date 1999-12-*01* "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQ8T0tYVQj74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8de78712-fc40-42f9-c906-fba6f82543e2"
      },
      "source": [
        "import pandas as pd\n",
        "london_housing = pd.read_csv(\"https://raw.githubusercontent.com/futureCodersSE/working-with-data/main/Data%20sets/housing_in_london_yearly_variables.csv\")\n",
        "new_london_housing= london_housing.drop_duplicates(subset = ['area'])\n",
        "new_london_housing"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>code</th>\n",
              "      <th>area</th>\n",
              "      <th>date</th>\n",
              "      <th>median_salary</th>\n",
              "      <th>life_satisfaction</th>\n",
              "      <th>mean_salary</th>\n",
              "      <th>recycling_pct</th>\n",
              "      <th>population_size</th>\n",
              "      <th>number_of_jobs</th>\n",
              "      <th>area_size</th>\n",
              "      <th>no_of_houses</th>\n",
              "      <th>borough_flag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>E09000001</td>\n",
              "      <td>city of london</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>33020.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>48922</td>\n",
              "      <td>0</td>\n",
              "      <td>6581.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>E09000002</td>\n",
              "      <td>barking and dagenham</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>21480.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>23620</td>\n",
              "      <td>3</td>\n",
              "      <td>162444.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>E09000003</td>\n",
              "      <td>barnet</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>19568.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>23128</td>\n",
              "      <td>8</td>\n",
              "      <td>313469.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>E09000004</td>\n",
              "      <td>bexley</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>18621.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>21386</td>\n",
              "      <td>18</td>\n",
              "      <td>217458.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>E09000005</td>\n",
              "      <td>brent</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>18532.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>20911</td>\n",
              "      <td>6</td>\n",
              "      <td>260317.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>E09000006</td>\n",
              "      <td>bromley</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>16720.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>21293</td>\n",
              "      <td>13</td>\n",
              "      <td>294902.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>E09000007</td>\n",
              "      <td>camden</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>23677.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>30249</td>\n",
              "      <td>13</td>\n",
              "      <td>190003.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>E09000008</td>\n",
              "      <td>croydon</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>19563.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>22205</td>\n",
              "      <td>13</td>\n",
              "      <td>332066.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>E09000009</td>\n",
              "      <td>ealing</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>20580.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>25046</td>\n",
              "      <td>12</td>\n",
              "      <td>302252.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>E09000010</td>\n",
              "      <td>enfield</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>19289.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>21006</td>\n",
              "      <td>9</td>\n",
              "      <td>272731.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>E09000011</td>\n",
              "      <td>greenwich</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>21236.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>22263</td>\n",
              "      <td>4</td>\n",
              "      <td>212168.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>E09000012</td>\n",
              "      <td>hackney</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>23249.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>39629</td>\n",
              "      <td>2</td>\n",
              "      <td>199087.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>E09000013</td>\n",
              "      <td>hammersmith and fulham</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>25000.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>28555</td>\n",
              "      <td>7</td>\n",
              "      <td>160634.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>E09000014</td>\n",
              "      <td>haringey</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>18783.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>21683</td>\n",
              "      <td>5</td>\n",
              "      <td>218559.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>E09000015</td>\n",
              "      <td>harrow</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>20596.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>22824</td>\n",
              "      <td>10</td>\n",
              "      <td>207909.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>E09000016</td>\n",
              "      <td>havering</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>17165.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>18786</td>\n",
              "      <td>8</td>\n",
              "      <td>225712.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>E09000017</td>\n",
              "      <td>hillingdon</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>24002.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>28854</td>\n",
              "      <td>11</td>\n",
              "      <td>245053.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>E09000018</td>\n",
              "      <td>hounslow</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>20155.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>24602</td>\n",
              "      <td>14</td>\n",
              "      <td>214298.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>E09000019</td>\n",
              "      <td>islington</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>25113.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>34180</td>\n",
              "      <td>2</td>\n",
              "      <td>175717.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>E09000020</td>\n",
              "      <td>kensington and chelsea</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>20646.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>28074</td>\n",
              "      <td>13</td>\n",
              "      <td>147678.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>E09000021</td>\n",
              "      <td>kingston upon thames</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>19302.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>22967</td>\n",
              "      <td>18</td>\n",
              "      <td>146003.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>E09000022</td>\n",
              "      <td>lambeth</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>23151.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>27930</td>\n",
              "      <td>8</td>\n",
              "      <td>266817.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>E09000023</td>\n",
              "      <td>lewisham</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>20580.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>23283</td>\n",
              "      <td>4</td>\n",
              "      <td>250310.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>E09000024</td>\n",
              "      <td>merton</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>18962.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>21867</td>\n",
              "      <td>11</td>\n",
              "      <td>185062.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>E09000025</td>\n",
              "      <td>newham</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>18862.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>20580</td>\n",
              "      <td>3</td>\n",
              "      <td>240517.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>E09000026</td>\n",
              "      <td>redbridge</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>19580.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>22087</td>\n",
              "      <td>8</td>\n",
              "      <td>238138.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>E09000027</td>\n",
              "      <td>richmond upon thames</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>22321.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>25832</td>\n",
              "      <td>na</td>\n",
              "      <td>172782.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>E09000028</td>\n",
              "      <td>southwark</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>22784.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>26994</td>\n",
              "      <td>3</td>\n",
              "      <td>247853.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>E09000029</td>\n",
              "      <td>sutton</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>19582.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>22725</td>\n",
              "      <td>27</td>\n",
              "      <td>179375.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>E09000030</td>\n",
              "      <td>tower hamlets</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>26376.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>37524</td>\n",
              "      <td>3</td>\n",
              "      <td>193507.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>E09000031</td>\n",
              "      <td>waltham forest</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>18547.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>19888</td>\n",
              "      <td>9</td>\n",
              "      <td>221057.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>E09000032</td>\n",
              "      <td>wandsworth</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>21321.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>24707</td>\n",
              "      <td>7</td>\n",
              "      <td>264220.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>E09000033</td>\n",
              "      <td>westminster</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>24447.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>36167</td>\n",
              "      <td>7</td>\n",
              "      <td>189233.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>E12000001</td>\n",
              "      <td>north east</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>16282.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>18351</td>\n",
              "      <td>5</td>\n",
              "      <td>2550314.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>E12000002</td>\n",
              "      <td>north west</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>16977.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>19609</td>\n",
              "      <td>7</td>\n",
              "      <td>6773115.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>E12000003</td>\n",
              "      <td>yorkshire and the humber</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>16527.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>18977</td>\n",
              "      <td>7</td>\n",
              "      <td>4956325.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>E12000004</td>\n",
              "      <td>east midlands</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>16392.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>18864</td>\n",
              "      <td>11</td>\n",
              "      <td>4152443.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>E12000005</td>\n",
              "      <td>west midlands</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>17000.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>19686</td>\n",
              "      <td>9</td>\n",
              "      <td>5271959.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>E12000006</td>\n",
              "      <td>east</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>18000.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>20866</td>\n",
              "      <td>14</td>\n",
              "      <td>5338722.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>E12000007</td>\n",
              "      <td>london</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>22487.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>29640</td>\n",
              "      <td>9</td>\n",
              "      <td>7153912.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>E12000008</td>\n",
              "      <td>south east</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>18737.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>22361</td>\n",
              "      <td>15</td>\n",
              "      <td>7955124.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>E12000009</td>\n",
              "      <td>south west</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>16727.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>19203</td>\n",
              "      <td>14</td>\n",
              "      <td>4880958.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>E13000001</td>\n",
              "      <td>inner london</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2750716.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>E13000002</td>\n",
              "      <td>outer london</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4403196.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>E92000001</td>\n",
              "      <td>england</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>17939.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>21561</td>\n",
              "      <td>10</td>\n",
              "      <td>49032872.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>K02000001</td>\n",
              "      <td>united kingdom</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>17803.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>21314</td>\n",
              "      <td>NaN</td>\n",
              "      <td>58684427.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>K03000001</td>\n",
              "      <td>great britain</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>17866.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>21379</td>\n",
              "      <td>NaN</td>\n",
              "      <td>57005421.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>K04000001</td>\n",
              "      <td>england and wales</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>17974.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>21549</td>\n",
              "      <td>NaN</td>\n",
              "      <td>51933471.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>N92000002</td>\n",
              "      <td>northern ireland</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>15798.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>19093</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1679006.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>S92000003</td>\n",
              "      <td>scotland</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>16914.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>19667</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5071950.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>W92000004</td>\n",
              "      <td>wales</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>16457.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>18486</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2900599.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         code                      area  ... no_of_houses  borough_flag\n",
              "0   E09000001            city of london  ...          NaN             1\n",
              "1   E09000002      barking and dagenham  ...          NaN             1\n",
              "2   E09000003                    barnet  ...          NaN             1\n",
              "3   E09000004                    bexley  ...          NaN             1\n",
              "4   E09000005                     brent  ...          NaN             1\n",
              "5   E09000006                   bromley  ...          NaN             1\n",
              "6   E09000007                    camden  ...          NaN             1\n",
              "7   E09000008                   croydon  ...          NaN             1\n",
              "8   E09000009                    ealing  ...          NaN             1\n",
              "9   E09000010                   enfield  ...          NaN             1\n",
              "10  E09000011                 greenwich  ...          NaN             1\n",
              "11  E09000012                   hackney  ...          NaN             1\n",
              "12  E09000013    hammersmith and fulham  ...          NaN             1\n",
              "13  E09000014                  haringey  ...          NaN             1\n",
              "14  E09000015                    harrow  ...          NaN             1\n",
              "15  E09000016                  havering  ...          NaN             1\n",
              "16  E09000017                hillingdon  ...          NaN             1\n",
              "17  E09000018                  hounslow  ...          NaN             1\n",
              "18  E09000019                 islington  ...          NaN             1\n",
              "19  E09000020    kensington and chelsea  ...          NaN             1\n",
              "20  E09000021      kingston upon thames  ...          NaN             1\n",
              "21  E09000022                   lambeth  ...          NaN             1\n",
              "22  E09000023                  lewisham  ...          NaN             1\n",
              "23  E09000024                    merton  ...          NaN             1\n",
              "24  E09000025                    newham  ...          NaN             1\n",
              "25  E09000026                 redbridge  ...          NaN             1\n",
              "26  E09000027      richmond upon thames  ...          NaN             1\n",
              "27  E09000028                 southwark  ...          NaN             1\n",
              "28  E09000029                    sutton  ...          NaN             1\n",
              "29  E09000030             tower hamlets  ...          NaN             1\n",
              "30  E09000031            waltham forest  ...          NaN             1\n",
              "31  E09000032                wandsworth  ...          NaN             1\n",
              "32  E09000033               westminster  ...          NaN             1\n",
              "33  E12000001                north east  ...          NaN             0\n",
              "34  E12000002                north west  ...          NaN             0\n",
              "35  E12000003  yorkshire and the humber  ...          NaN             0\n",
              "36  E12000004             east midlands  ...          NaN             0\n",
              "37  E12000005             west midlands  ...          NaN             0\n",
              "38  E12000006                      east  ...          NaN             0\n",
              "39  E12000007                    london  ...          NaN             0\n",
              "40  E12000008                south east  ...          NaN             0\n",
              "41  E12000009                south west  ...          NaN             0\n",
              "42  E13000001              inner london  ...          NaN             0\n",
              "43  E13000002              outer london  ...          NaN             0\n",
              "44  E92000001                   england  ...          NaN             0\n",
              "45  K02000001            united kingdom  ...          NaN             0\n",
              "46  K03000001             great britain  ...          NaN             0\n",
              "47  K04000001         england and wales  ...          NaN             0\n",
              "48  N92000002          northern ireland  ...          NaN             0\n",
              "49  S92000003                  scotland  ...          NaN             0\n",
              "50  W92000004                     wales  ...          NaN             0\n",
              "\n",
              "[51 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQ_tQG_3WBXn"
      },
      "source": [
        "# Normalising Data  \n",
        "When we normalise data, we remodel a numeric column in a dataframe to be on a standard scale (e.g. 0 or 1).   \n",
        "\n",
        "For example if we had a column of BMI scores, we could normalise that column so that all scores greater than or equal to 25 were recoded to the value 1 (bad) and all scores less than 25 were recoded to 0 (good).  \n",
        "\n",
        "To normalise we need to:\n",
        "*   write a function, with the dataframe as a parameter, which will look at each row in dataframe column and return either a value in the normalised scale (e.g. 0,1 or 1,2,3,4) depending on that value.\n",
        "\n",
        "For example:  \n",
        "```\n",
        "def normalise_bmi(df):\n",
        "  if df['bmi'] >= 25:\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "df[\"bmi\"] = df.apply(normalise_bmi, axis=1)\n",
        "```\n",
        "This code reassigns the values in the column \"bmi\" by sending each row one after the other to the normalise_bmi function, which will check the value in the \"bmi\" column and return either 0 or 1 depending on the value in the \"bmi\" column."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8KPmy2_NVh1"
      },
      "source": [
        "### Exercise 7 - normalise data set\n",
        "---\n",
        "\n",
        "Create a function called **normalise_income(df)** that will return the values 1, 2 or 3 to represent low income, middle income and high income.  If the value in `df['median_salary']` is less than 27441 (the median), return 1, otherwise if it is less than 30932 (the upper quartile) return 2 and otherwise return 3.\n",
        "\n",
        "Apply the normalise_income(df) function to the `median_salary` column.\n",
        "\n",
        "*NOTE:  this operation will change the original dataframe so if you run it twice, everything in the median_salary column will change to 1 (as it had already been reduced to 1, 2 or 3 - if this happens, run the code in Exercise 4 again to get the original data again from the file.*\n",
        "\n",
        "**Test output**:  \n",
        "The maximum value of the column df['median_salary'] will be 3 and the minimum value will be 1  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktylpCl7QjGJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "137b64c1-4020-433c-d807-785d0fa5da4c"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/futureCodersSE/working-with-data/main/Data%20sets/housing_in_london_yearly_variables.csv\")\n",
        "def normalise_df(df):\n",
        "  if df['median_salary'] <= 274441:\n",
        "    return 1\n",
        "  elif df['median_salary'] <= 30932:\n",
        "    return 2\n",
        "  else:\n",
        "    return 3\n",
        "df['median_salary'] = df.apply(normalise_df,axis=1)\n",
        "df[\"median_salary\"]\n"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       1\n",
              "1       1\n",
              "2       1\n",
              "3       1\n",
              "4       1\n",
              "       ..\n",
              "1066    1\n",
              "1067    1\n",
              "1068    1\n",
              "1069    1\n",
              "1070    1\n",
              "Name: median_salary, Length: 1071, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCrIEyMjSYTI"
      },
      "source": [
        "### Exercise 8 - normalise the number of jobs column\n",
        "---\n",
        "\n",
        "Using what you have learnt from Exercise 7:  \n",
        "*  use `df.describe()` to find the median, upper quartile and maximum for the number_of_jobs column  \n",
        "*  create a function called **normalise_jobs(df)** that will return 1 if the `number_of_jobs` is below the median, 2 if the `number_of_jobs` is below the upper quartile or 3 otherwise.\n",
        "*  normalise the `number_of_jobs` column by applying the function `normalise_jobs`.\n",
        "\n",
        "**Test output**:  \n",
        "The maximum value of the column df['number_of_jobs'] will be 3 and the minimum value will be 1  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uAyBYDb92oL",
        "outputId": "6a971496-001b-44a8-c287-e9eab8f33422"
      },
      "source": [
        "df[\"number_of_jobs\"].describe()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    9.310000e+02\n",
              "mean     3.188095e+06\n",
              "std      8.058302e+06\n",
              "min      4.700000e+04\n",
              "25%      9.450000e+04\n",
              "50%      1.570000e+05\n",
              "75%      2.217000e+06\n",
              "max      3.575000e+07\n",
              "Name: number_of_jobs, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giYXovr-T7TB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "203f7502-b998-4b71-c660-dc2924a86977"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/futureCodersSE/working-with-data/main/Data%20sets/housing_in_london_yearly_variables.csv\")\n",
        "df[\"number_of_jobs\"].describe()\n",
        "def normalise_jobs(df):\n",
        "  if df['number_of_jobs'] <= 1.570000e+05:\n",
        "    return 1\n",
        "  elif df['number_of_jobs'] <= 2.217000e+06:\n",
        "    return 2\n",
        "  else:\n",
        "    return 3\n",
        "df['number_of_jobs'] = df.apply(normalise_jobs,axis=1)\n",
        "df[\"number_of_jobs\"].describe()\n"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    1071.000000\n",
              "mean        1.911298\n",
              "std         0.882103\n",
              "min         1.000000\n",
              "25%         1.000000\n",
              "50%         2.000000\n",
              "75%         3.000000\n",
              "max         3.000000\n",
              "Name: number_of_jobs, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-akqnUbYVblH"
      },
      "source": [
        "## Exercise 9 - normalise into a new column\n",
        "---\n",
        "\n",
        "Create a new function and code to normalise the `no_of_houses` column BUT this time, instead of assigning the result to `df['no_of_houses']` assign it to a new column called `df['housing_volume']`\n",
        "\n",
        "**Test output**:  \n",
        "The maximum value of the column df['housing_volume'] will be 3 and the minimum value will be 1 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SLCtLMaT_ot0",
        "outputId": "b2b36127-1969-4fa0-8e62-896cf6f6be77"
      },
      "source": [
        "df[\"no_of_houses\"].describe()"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    6.660000e+02\n",
              "mean     8.814682e+05\n",
              "std      3.690376e+06\n",
              "min      5.009000e+03\n",
              "25%      8.763550e+04\n",
              "50%      1.024020e+05\n",
              "75%      1.262760e+05\n",
              "max      2.417217e+07\n",
              "Name: no_of_houses, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnQsE4znV6nD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "934b6c7d-62f8-4595-c68c-8bed2ba8f17c"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/futureCodersSE/working-with-data/main/Data%20sets/housing_in_london_yearly_variables.csv\")\n",
        "df[\"no_of_houses\"].describe()\n",
        "def normalise_houses(df):\n",
        "  if df['no_of_houses'] <= 1.024020e+05:\n",
        "    return 1\n",
        "  elif df['no_of_houses'] <= 1.262760e+05:\n",
        "    return 2\n",
        "  else:\n",
        "    return 3\n",
        "df['housing_volume'] = df.apply(normalise_houses,axis=1)\n",
        "df[\"housing_volume\"].describe()"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    1071.000000\n",
              "mean        2.223156\n",
              "std         0.892160\n",
              "min         1.000000\n",
              "25%         1.000000\n",
              "50%         3.000000\n",
              "75%         3.000000\n",
              "max         3.000000\n",
              "Name: housing_volume, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_FaL31EXHZX"
      },
      "source": [
        "### Exercise 10 - normalise boroughs\n",
        "---\n",
        "\n",
        "Normalise the `area_size` column so that all values below mean are represented as 0 and otherwise are 1.  Assign the output to a new column called `area_size_normalised`.  \n",
        "\n",
        "**Test output**:  \n",
        "`area_size_normalised` column will contain both 0s and 1s.  The position of the first row with value 1 will be 0 and the position of the first row with value 0 will be 102.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45VygxtRAnyr",
        "outputId": "7d00343f-8aa4-445d-b32f-937af9b6be13"
      },
      "source": [
        "df[\"area_size\"].describe()"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    6.660000e+02\n",
              "mean     3.724903e+05\n",
              "std      2.157060e+06\n",
              "min      3.150000e+02\n",
              "25%      2.960000e+03\n",
              "50%      4.323000e+03\n",
              "75%      8.220000e+03\n",
              "max      1.330373e+07\n",
              "Name: area_size, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doIZ9M0UXkkv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5463bb17-15fb-4725-c068-26ad309f65e1"
      },
      "source": [
        "#Normalise the area_size column so that all values below mean are represented as 0 and otherwise are 1. Assign the output to a new column called area_size_normalised.\n",
        "import pandas as pd\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/futureCodersSE/working-with-data/main/Data%20sets/housing_in_london_yearly_variables.csv\")\n",
        "df[\"area_size\"].describe()\n",
        "def normalise_area(df):\n",
        "  if df['area_size'] <= 3.724903e+05:\n",
        "    return 0\n",
        "  else:\n",
        "    return 1\n",
        "df['area_size_normalised'] = df.apply(normalise_area,axis=1)\n",
        "df[\"area_size_normalised\"].describe()"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    1071.000000\n",
              "mean        0.394958\n",
              "std         0.489070\n",
              "min         0.000000\n",
              "25%         0.000000\n",
              "50%         0.000000\n",
              "75%         1.000000\n",
              "max         1.000000\n",
              "Name: area_size_normalised, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    }
  ]
}